{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ed5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the necessary libraries\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e16642",
   "metadata": {},
   "source": [
    "# 2. Preprocess the data\n",
    "The image data cannot be fed directly into the model so we need to perform some operations and process the data to make it ready for our neural network. The dimension of the training data is (60000,28,28). The CNN model will require one more dimension so we reshape the matrix to shape (60000,28,28,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce70859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc939f5",
   "metadata": {},
   "source": [
    "# 3. Create the model\n",
    "Now we will create our CNN model in Python data science project. A CNN model generally consists of convolutional and pooling layers. It works better for data that are represented as grid structures, this is the reason why CNN works well for image classification problems. The dropout layer is used to deactivate some of the neurons and while training, it reduces offer fitting of the model. We will then compile the model with the Adadelta optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25e2ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamalraj/Desktop/  /Data science/projects/Deep Learning Project – Handwritten Digit Recognition using Python/.venv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b66004",
   "metadata": {},
   "source": [
    "# 4. Train the model\n",
    "The model.fit() function of Keras will start the training of the model. It takes the training data, validation data, epochs, and batch size.\n",
    "\n",
    "It takes some time to train the model. After training, we save the weights and model definition in the ‘mnist.h5’ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf32122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9254 - loss: 0.4795 - val_accuracy: 0.9842 - val_loss: 0.2345\n",
      "Epoch 2/20\n",
      "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.8750 - loss: 0.5989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamalraj/Desktop/  /Data science/projects/Deep Learning Project – Handwritten Digit Recognition using Python/.venv/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.5989 - val_accuracy: 0.9847 - val_loss: 0.2333\n",
      "Epoch 3/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.9476 - loss: 0.3422 - val_accuracy: 0.9815 - val_loss: 0.2103\n",
      "Epoch 4/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.4622 - val_accuracy: 0.9807 - val_loss: 0.2123\n",
      "Epoch 5/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 43ms/step - accuracy: 0.9533 - loss: 0.3035 - val_accuracy: 0.9865 - val_loss: 0.1819\n",
      "Epoch 6/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.2919 - val_accuracy: 0.9869 - val_loss: 0.1805\n",
      "Epoch 7/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 40ms/step - accuracy: 0.9581 - loss: 0.2779 - val_accuracy: 0.9908 - val_loss: 0.1748\n",
      "Epoch 8/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.2525 - val_accuracy: 0.9905 - val_loss: 0.1748\n",
      "Epoch 9/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 40ms/step - accuracy: 0.9602 - loss: 0.2739 - val_accuracy: 0.9827 - val_loss: 0.1950\n",
      "Epoch 10/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.2520 - val_accuracy: 0.9826 - val_loss: 0.1980\n",
      "Epoch 11/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.9604 - loss: 0.2700 - val_accuracy: 0.9888 - val_loss: 0.1782\n",
      "Epoch 12/20\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.2824 - val_accuracy: 0.9882 - val_loss: 0.1792\n",
      "Epoch 13/20\n",
      "\u001b[1m475/937\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 40ms/step - accuracy: 0.9630 - loss: 0.2634"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "          steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ca7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model as mnist.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('mnist.h5')\n",
    "print(\"Saving the model as mnist.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9257abf1",
   "metadata": {},
   "source": [
    "# 5. Evaluate the model\n",
    "We have 10,000 images in our dataset which will be used to evaluate how good our model works. The testing data was not involved in the training of the data therefore, it is new data for our model. The MNIST dataset is well balanced so we can get around 99% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c416fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.17805740237236023\n",
      "Test accuracy: 0.9894999861717224\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e6ddb",
   "metadata": {},
   "source": [
    "# 6. Create GUI to predict digits\n",
    "Now for the GUI, we have created a new file in which we build an interactive window to draw digits on canvas and with a button, we can recognize the digit. The Tkinter library comes in the Python standard library. We have created a function predict_digit() that takes the image as input and then uses the trained model to predict the digit.\n",
    "\n",
    "Then we create the App class which is responsible for building the GUI for our app. We create a canvas where we can draw by capturing the mouse event and with a button, we trigger the predict_digit() function and display the results.\n",
    "\n",
    "Here’s the full code for our gui_digit_recognizer.py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c82b63e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     73\u001b[39m             \u001b[38;5;28mself\u001b[39m.label.configure(text=\u001b[38;5;28mstr\u001b[39m(digit) + \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(acc * \u001b[32m100\u001b[39m)) + \u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     75\u001b[39m app = App()\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tkinter/__init__.py:1485\u001b[39m, in \u001b[36mMisc.mainloop\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n=\u001b[32m0\u001b[39m):\n\u001b[32m   1484\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1485\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import filedialog as fd # File dialog to open files in tkinter GUI app \n",
    "import tkinter as tk\n",
    "import numpy as np\n",
    "import mss\n",
    "import mss.tools\n",
    "from PIL import Image\n",
    "\n",
    "# Load the model outside the main loop\n",
    "model = load_model('mnist.h5')\n",
    "\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "\n",
    "        self.x = self.y = 0\n",
    "        self.prev_x = self.prev_y = None  # Track previous coordinates\n",
    "\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg=\"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 18))\n",
    "        self.classify_btn = tk.Button(self, text=\"Recognise\", command=self.classify_handwriting)\n",
    "        self.button_clear = tk.Button(self, text=\"Clear\", command=self.clear_all)\n",
    "\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W)\n",
    "        self.label.grid(row=0, column=1, pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "\n",
    "        # Bind the mouse events\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "\n",
    "    def classify_handwriting(self):\n",
    "        with mss.mss() as sct:\n",
    "            monitor = {\"top\": 0, \"left\": 0, \"width\": 150, \"height\": 150}  # Reduced size\n",
    "            im = sct.grab(monitor)\n",
    "            img = Image.frombytes(\"RGB\", im.size, im.bgra, \"raw\", \"BGRX\")\n",
    "            img = img.convert('L')  # Convert directly to grayscale\n",
    "            img = img.resize((28, 28))\n",
    "            img = np.array(img)\n",
    "            img = img.reshape(1, 28, 28, 1)\n",
    "            img = img / 255.0\n",
    "            res = model.predict([img])[0]\n",
    "            digit = np.argmax(res)\n",
    "            acc = max(res)\n",
    "            self.label.configure(text=str(digit) + ', ' + str(int(acc * 100)) + '%')\n",
    "\n",
    "    def draw_lines(self, event):\n",
    "        self.prev_x = self.x\n",
    "        self.prev_y = self.y\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r = 5  # Adjust the line thickness\n",
    "        if self.prev_x and self.prev_y:\n",
    "            self.canvas.create_line(self.prev_x, self.prev_y, self.x, self.y, width=r, fill='black')\n",
    "\n",
    "app = App()\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435076f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m score = model.evaluate(\u001b[43mx_test\u001b[49m, y_test, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTest loss:\u001b[39m\u001b[33m'\u001b[39m, score[\u001b[32m0\u001b[39m])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTest accuracy:\u001b[39m\u001b[33m'\u001b[39m, score[\u001b[32m1\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
